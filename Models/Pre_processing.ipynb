{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Pre_processing.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bJBVJ3wQxpx_","executionInfo":{"status":"ok","timestamp":1636573657859,"user_tz":-480,"elapsed":524,"user":{"displayName":"Loe Daniel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08421922444215535702"}},"outputId":"293cb72c-8fc7-4bf4-96cc-0b37c8f511d9"},"source":["# Mount google drive where dataset is stored at\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"bJBVJ3wQxpx_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"489fe531"},"source":["# Import Pandas\n","import pandas as pd"],"id":"489fe531","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2c622c38"},"source":["### Load the fold_frontal_data.txt"],"id":"2c622c38"},{"cell_type":"code","metadata":{"id":"81ed7e78"},"source":["# Define the google drive path where data is stored\n","base_path = '/content/drive/MyDrive/CZ4042 Project Assignment 2/Models/'\n","\n","# Read the frontal_data into dataframes for processing\n","fold_frontal_0_df = pd.read_csv(base_path + \"../fold_frontal_0_data.txt\", sep='\\t')\n","fold_frontal_1_df = pd.read_csv(base_path + \"../fold_frontal_1_data.txt\", sep='\\t')\n","fold_frontal_2_df = pd.read_csv(base_path + \"../fold_frontal_2_data.txt\", sep='\\t')\n","fold_frontal_3_df = pd.read_csv(base_path + \"../fold_frontal_3_data.txt\", sep='\\t')\n","fold_frontal_4_df = pd.read_csv(base_path + \"../fold_frontal_4_data.txt\", sep='\\t')"],"id":"81ed7e78","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9c8fec3a"},"source":["### Define Functions"],"id":"9c8fec3a"},{"cell_type":"code","metadata":{"id":"957665e5"},"source":["# Function to convert .txt file f to 0 and m to 1\n","def binary_classification_of_gender(gender):\n","    if gender == 'f':\n","        return 0\n","    elif gender == 'm':\n","        return 1\n","    else:\n","        return -1\n","\n","# Function to create the absoluate path where the image is located\n","def createAbsolutePath(user_id, face_id, original_image):\n","    absolutePath = '../aligned/' + user_id + '/landmark_aligned_face.' + str(face_id) + '.' + original_image\n","    return absolutePath"],"id":"957665e5","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"678dcf2e"},"source":["### Create Absolute Path for each frontal_fold_df"],"id":"678dcf2e"},{"cell_type":"code","metadata":{"id":"822f3431"},"source":["fold_0_data_path = []\n","\n","# Go through each frontal_0_data.txt and create the absolute path for each image\n","if len(fold_frontal_0_df) > 0:\n","    for i in range(len(fold_frontal_0_df)):\n","        fold_0_data_path.append(createAbsolutePath(fold_frontal_0_df['user_id'][i], fold_frontal_0_df['face_id'][i], fold_frontal_0_df['original_image'][i]))\n","    fold_frontal_0_df['data_path'] = fold_0_data_path\n","    fold_frontal_0_df = fold_frontal_0_df[['data_path', 'gender']]"],"id":"822f3431","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c525afd"},"source":["fold_1_data_path = []\n","\n","# Go through each frontal_1_data.txt and create the absolute path for each image\n","if len(fold_frontal_1_df) > 0:\n","    for i in range(len(fold_frontal_1_df)):\n","        fold_1_data_path.append(createAbsolutePath(fold_frontal_1_df['user_id'][i], fold_frontal_1_df['face_id'][i], fold_frontal_1_df['original_image'][i]))\n","    fold_frontal_1_df['data_path'] = fold_1_data_path\n","    fold_frontal_1_df = fold_frontal_1_df[['data_path', 'gender']]"],"id":"1c525afd","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8KYK8QX3RE3"},"source":[""],"id":"s8KYK8QX3RE3","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f11fb718"},"source":["fold_2_data_path = []\n","\n","# Go through each frontal_2_data.txt and create the absolute path for each image\n","if len(fold_frontal_2_df) > 0:\n","    for i in range(len(fold_frontal_2_df)):\n","        fold_2_data_path.append(createAbsolutePath(fold_frontal_2_df['user_id'][i], fold_frontal_2_df['face_id'][i], fold_frontal_2_df['original_image'][i]))\n","    fold_frontal_2_df['data_path'] = fold_2_data_path\n","    fold_frontal_2_df = fold_frontal_2_df[['data_path', 'gender']]"],"id":"f11fb718","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cf522c24"},"source":["fold_3_data_path = []\n","\n","# Go through each frontal_3_data.txt and create the absolute path for each image\n","if len(fold_frontal_3_df) > 0:\n","    for i in range(len(fold_frontal_3_df)):\n","        fold_3_data_path.append(createAbsolutePath(fold_frontal_3_df['user_id'][i], fold_frontal_3_df['face_id'][i], fold_frontal_3_df['original_image'][i]))\n","    fold_frontal_3_df['data_path'] = fold_3_data_path\n","    fold_frontal_3_df = fold_frontal_3_df[['data_path', 'gender']]"],"id":"cf522c24","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e24bf3cb"},"source":["fold_4_data_path = []\n","\n","# Go through each frontal_4_data.txt and create the absolute path for each image\n","if len(fold_frontal_4_df) > 0:\n","    for i in range(len(fold_frontal_4_df)):\n","        fold_4_data_path.append(createAbsolutePath(fold_frontal_4_df['user_id'][i], fold_frontal_4_df['face_id'][i], fold_frontal_4_df['original_image'][i]))\n","    fold_frontal_4_df['data_path'] = fold_4_data_path\n","    fold_frontal_4_df = fold_frontal_4_df[['data_path', 'gender']]"],"id":"e24bf3cb","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"50905b84"},"source":["### Combine the dataframes into one single df"],"id":"50905b84"},{"cell_type":"code","metadata":{"id":"d1315ea4"},"source":["# Combine all frontal_fold dfs into a singular combined df\n","combined_dfs = pd.concat([fold_frontal_0_df, fold_frontal_1_df, fold_frontal_2_df, fold_frontal_3_df, fold_frontal_4_df])"],"id":"d1315ea4","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3b8a8fc9"},"source":["# Apply the binary_classification_of_gender function\n","combined_dfs['gender'] = combined_dfs['gender'].apply(binary_classification_of_gender)\n","\n","# Remove any records with unknown gender values\n","processed_path_and_gender = combined_dfs[combined_dfs['gender'] != -1]"],"id":"3b8a8fc9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcMO3V2bXqAT","executionInfo":{"status":"ok","timestamp":1636573658593,"user_tz":-480,"elapsed":7,"user":{"displayName":"Loe Daniel","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08421922444215535702"}},"outputId":"d28ca327-6f38-49b5-dc75-5d2cd4bbdb23"},"source":["processed_path_and_gender.shape"],"id":"PcMO3V2bXqAT","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(12194, 2)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"d763c55b"},"source":["### Save files"],"id":"d763c55b"},{"cell_type":"code","metadata":{"id":"dcae6d1e"},"source":["# Generate the csv file\n","\n","processed_path_and_gender = processed_path_and_gender.to_csv(base_path + r'/processed_path_and_gender.txt', index=None, sep='\\t', mode='a')"],"id":"dcae6d1e","execution_count":null,"outputs":[]}]}