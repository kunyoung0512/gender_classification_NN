{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"celeb-a-pretrain.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"TFUU_FQzHg3N"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-10-28T02:03:36.348707Z","iopub.execute_input":"2021-10-28T02:03:36.349085Z","iopub.status.idle":"2021-10-28T02:03:41.719985Z","shell.execute_reply.started":"2021-10-28T02:03:36.349055Z","shell.execute_reply":"2021-10-28T02:03:41.719097Z"},"trusted":true,"id":"7oy9te2vHg3R"},"source":["import wandb\n","from wandb.keras import WandbCallback\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PoWtyg9fHg3S"},"source":["# Load dataset"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-10-28T02:03:41.721832Z","iopub.execute_input":"2021-10-28T02:03:41.722168Z","iopub.status.idle":"2021-10-28T02:03:42.778123Z","shell.execute_reply.started":"2021-10-28T02:03:41.722138Z","shell.execute_reply":"2021-10-28T02:03:42.777301Z"},"trusted":true,"id":"ZbsfDh0eHg3T"},"source":["df = pd.read_csv('/kaggle/input/celeba-dataset/list_attr_celeba.csv')\n","df['datadir'] = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/' + df['image_id'].astype(str)\n","df['gender'] = df['Male']\n","df['gender'] = df['gender'].replace(-1,0)\n","df = df[['datadir','gender']]\n","train_df, test_df = train_test_split(df, test_size=0.1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGoG-kxQHg3U"},"source":["# Model"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-10-28T02:03:42.779435Z","iopub.execute_input":"2021-10-28T02:03:42.779769Z","iopub.status.idle":"2021-10-28T07:11:54.567314Z","shell.execute_reply.started":"2021-10-28T02:03:42.779734Z","shell.execute_reply":"2021-10-28T07:11:54.566418Z"},"trusted":true,"id":"BHd17bfAHg3V","outputId":"77a8115e-6520-4166-fb3c-e1441908670a"},"source":["defaults = {\n","    'epochs': 20,\n","    'batch_size': 128,\n","    'fc1_num_neurons': 512,\n","    'fc2_num_neurons': 512,\n","    'fc3_num_neurons': 512,\n","    'seed': 7,\n","    'learning_rate': 3e-4,\n","    'optimizer': 'adam',\n","    'hidden_activation': 'relu',\n","    'output_activation': 'sigmoid',\n","    'loss_function': 'binary_crossentropy',\n","    'metrics': ['accuracy'],\n","}\n","\n","wandb.init(config=defaults, resume=True, name='For Tuned Model', project='CelebA Runs', notes='pretraining for tuned model, 0.1 test split')\n","config = wandb.config\n","\n","# Load images into keras image generator \n","datagen_train = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",")\n","datagen_test = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",")\n","\n","train_generator = datagen_train.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='datadir',\n","    y_col='gender',\n","    batch_size=config.batch_size,\n","    seed=config.seed,\n","    shuffle=True,\n","    class_mode='raw',\n","    target_size=(224,224),\n",")\n","\n","test_generator = datagen_test.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='datadir',\n","    y_col='gender',\n","    batch_size=config.batch_size,\n","    seed=config.seed,\n","    shuffle=True,\n","    class_mode='raw',\n","    target_size=(224,224),\n",")\n","\n","# Define model\n","mobile_net_v2 = tf.keras.applications.MobileNetV2(\n","    include_top=False,\n","    pooling='avg',\n","    weights='imagenet',\n","    input_shape=(224,224,3),\n",")\n","mobile_net_v2.trainable = True\n","\n","fc1 = tf.keras.layers.Dense(config.fc1_num_neurons,activation=config.hidden_activation)\n","fc2 = tf.keras.layers.Dense(config.fc2_num_neurons,activation=config.hidden_activation)\n","fc3 = tf.keras.layers.Dense(config.fc3_num_neurons,activation=config.hidden_activation)\n","bn1 = tf.keras.layers.BatchNormalization()\n","bn2 = tf.keras.layers.BatchNormalization()\n","bn3 = tf.keras.layers.BatchNormalization()\n","bn4 = tf.keras.layers.BatchNormalization()\n","\n","model = tf.keras.models.Sequential([\n","    mobile_net_v2,\n","    tf.keras.layers.Flatten(),\n","    bn1,\n","    fc1,\n","    bn2,\n","    fc2,\n","    bn3,\n","    fc3,\n","    bn4,\n","    tf.keras.layers.Dense(1, activation=config.output_activation),\n","])\n","model.summary()\n","\n","# Compile model \n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n","    loss=config.loss_function,\n","    metrics=config.metrics,\n",")\n","\n","model.fit(\n","    train_generator,\n","    validation_data=test_generator,\n","    shuffle=True,\n","    epochs=config.epochs,\n","    callbacks=[WandbCallback()],\n",")\n","model.save_weights('model_celeba_tune.h5') \n","# run.finish()"],"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n                Tracking run with wandb version 0.10.8<br/>\n                Syncing run <strong style=\"color:#cdcd00\">For Tuned Model</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/kunyoung0512/CelebA%20Runs\" target=\"_blank\">https://wandb.ai/kunyoung0512/CelebA%20Runs</a><br/>\n                Run page: <a href=\"https://wandb.ai/kunyoung0512/CelebA%20Runs/runs/3tcu1xo0\" target=\"_blank\">https://wandb.ai/kunyoung0512/CelebA%20Runs/runs/3tcu1xo0</a><br/>\n                Run data is saved locally in <code>wandb/run-20211028_020355-3tcu1xo0</code><br/><br/>\n            "},"metadata":{}},{"name":"stdout","text":"Found 182339 validated image filenames.\nFound 20260 validated image filenames.\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9412608/9406464 [==============================] - 0s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nmobilenetv2_1.00_224 (Functi (None, 1280)              2257984   \n_________________________________________________________________\nflatten (Flatten)            (None, 1280)              0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1280)              5120      \n_________________________________________________________________\ndense (Dense)                (None, 512)               655872    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_2 (Dense)              (None, 512)               262656    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 512)               2048      \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 3,450,945\nTrainable params: 3,411,201\nNon-trainable params: 39,744\n_________________________________________________________________\nEpoch 1/20\n1425/1425 [==============================] - 1338s 939ms/step - loss: 0.0765 - accuracy: 0.9717 - val_loss: 0.0766 - val_accuracy: 0.9800\nEpoch 2/20\n1425/1425 [==============================] - 890s 624ms/step - loss: 0.0403 - accuracy: 0.9860 - val_loss: 0.0627 - val_accuracy: 0.9827\nEpoch 3/20\n1425/1425 [==============================] - 886s 622ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.0632 - val_accuracy: 0.9836\nEpoch 4/20\n1425/1425 [==============================] - 880s 618ms/step - loss: 0.0260 - accuracy: 0.9911 - val_loss: 0.0849 - val_accuracy: 0.9802\nEpoch 5/20\n1425/1425 [==============================] - 889s 624ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0617 - val_accuracy: 0.9819\nEpoch 6/20\n1425/1425 [==============================] - 889s 624ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0764 - val_accuracy: 0.9840\nEpoch 7/20\n1425/1425 [==============================] - 904s 634ms/step - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0588 - val_accuracy: 0.9827\nEpoch 8/20\n1425/1425 [==============================] - 891s 625ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 0.1899 - val_accuracy: 0.9731\nEpoch 9/20\n1425/1425 [==============================] - 879s 617ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0668 - val_accuracy: 0.9841\nEpoch 10/20\n1425/1425 [==============================] - 885s 621ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.0677 - val_accuracy: 0.9860\nEpoch 11/20\n1425/1425 [==============================] - 891s 625ms/step - loss: 0.0091 - accuracy: 0.9968 - val_loss: 0.0583 - val_accuracy: 0.9843\nEpoch 12/20\n1425/1425 [==============================] - 888s 623ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.1708 - val_accuracy: 0.9621\nEpoch 13/20\n1425/1425 [==============================] - 886s 622ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0830 - val_accuracy: 0.9852\nEpoch 14/20\n1425/1425 [==============================] - 886s 622ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0859 - val_accuracy: 0.9827\nEpoch 15/20\n1425/1425 [==============================] - 888s 623ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1033 - val_accuracy: 0.9745\nEpoch 16/20\n1425/1425 [==============================] - 884s 620ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.0826 - val_accuracy: 0.9848\nEpoch 17/20\n1425/1425 [==============================] - 886s 622ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0808 - val_accuracy: 0.9829\nEpoch 18/20\n1425/1425 [==============================] - 888s 623ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0852 - val_accuracy: 0.9836\nEpoch 19/20\n1425/1425 [==============================] - 889s 624ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0982 - val_accuracy: 0.9710\nEpoch 20/20\n1425/1425 [==============================] - 889s 624ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.1019 - val_accuracy: 0.9803\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"trusted":true,"id":"xDtoMo22Hg3X"},"source":[""],"execution_count":null,"outputs":[]}]}